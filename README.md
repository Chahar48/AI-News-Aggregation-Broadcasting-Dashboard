# AI-News-Aggregation-Broadcasting-Dashboard
Built an AI News Aggregation &amp; Broadcasting Dashboard as an MVP. The system ingests AI-related news, normalizes and deduplicates it, stores it in PostgreSQL, and exposes APIs using FastAPI. A React/Next.js dashboard displays the news feed, allows users to favorite items, and broadcast selected news via Email, LinkedIn, WhatsApp, Blog, or Newsletter

ğŸ“° AI News Aggregation & Broadcasting Dashboard (MVP)

Author: Mukesh Kumar
Project Type: MVP Prototype
Backend: FastAPI + PostgreSQL
Frontend: Next.js (React)
AI Integration: Groq (summarization & content generation â€“ mocked where required)

ğŸ“Œ Project Overview

This project is an MVP AI-powered news aggregation dashboard that collects AI-related news from multiple high-signal sources, deduplicates them, displays them in a dashboard, allows users to mark favorites, and broadcast selected news via Email, LinkedIn, WhatsApp, Blog, or Newsletter (mocked).

The goal of this MVP is to demonstrate system design, backend engineering, data handling, and AI integration, not to build a full-scale production scraper.


ğŸ¯ Key Features Implemented

âœ… AI News Feed Dashboard
âœ… Deterministic / Seeded Ingestion (Reliable MVP Mode)
âœ… Deduplication Logic
âœ… PostgreSQL Database Integration
âœ… Favorites System
âœ… Broadcast Simulation (Email / LinkedIn / WhatsApp / Newsletter)
âœ… Modular Backend Architecture
âœ… Frontend Dashboard (React / Next.js)


ğŸ§  Why Seeded Data (Important Design Decision)

Live scraping from 20+ sources is inherently unreliable for interview demos due to:

Rate limits
RSS/API downtime
HTML structure changes

Therefore, this MVP uses deterministic seeded data to ensure:

âœ” Dashboard always works
âœ” Favorites always work
âœ” Broadcast always works
âœ” Zero demo risk

The ingestion pipeline is live-ready and can be switched to real sources with minimal changes.

ğŸ§© System Architecture
[Seeded / RSS Sources]
        â†“
[Fetcher Service]
        â†“
[Parser & Normalizer]
        â†“
[Deduplication Logic]
        â†“
[PostgreSQL Database]
        â†“
[FastAPI REST APIs]
        â†“
[Next.js Dashboard]
        â†“
[Broadcast Services (Mocked)]

ğŸ—„ï¸ Database Schema (PostgreSQL)
| Table            | Purpose                         |
| ---------------- | ------------------------------- |
| `sources`        | Registered news sources         |
| `news_items`     | Aggregated AI news              |
| `favorites`      | User-favorited news             |
| `broadcast_logs` | Broadcast history               |
| `users`          | Optional user table (MVP-ready) |


ğŸ›  Tech Stack

#Backend

FastAPI
SQLAlchemy ORM
PostgreSQL
Pydantic
Uvicorn

#Frontend

Next.js
React
Tailwind CSS
SWR

#AI

Groq (used for content generation & summaries)
Mocked safely for MVP reliability


```text
ai-news-dashboard/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ config.py                # Environment & app configuration
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚   â”‚       â”œâ”€â”€ news.py           # News listing & retrieval APIs
â”‚   â”‚   â”‚       â”œâ”€â”€ favorites.py      # Favorites management APIs
â”‚   â”‚   â”‚       â”œâ”€â”€ broadcast.py      # Broadcast execution & logs APIs
â”‚   â”‚   â”‚       â””â”€â”€ admin.py          # Admin & source management APIs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ db.py                # Database session & engine
â”‚   â”‚   â”‚   â”œâ”€â”€ orm_models.py        # SQLAlchemy ORM models
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic request/response schemas
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fetcher.py       # Source fetching abstraction
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ parsers.py       # RSS / source parsers
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ schedule.py      # Ingestion scheduling logic
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py        # Data normalization layer
â”‚   â”‚   â”‚   â”œâ”€â”€ deduper.py           # Deduplication logic
â”‚   â”‚   â”‚   â”œâ”€â”€ embedder.py          # Embedding / semantic utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ summarizer.py        # AI-powered summarization
â”‚   â”‚   â”‚   â””â”€â”€ broadcaster.py       # Broadcast engine
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”‚   â”œâ”€â”€ worker.py            # Background worker (Celery/RQ-ready)
â”‚   â”‚   â”‚   â””â”€â”€ jobs.py              # Async / scheduled jobs
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ logger.py            # Centralized logging
â”‚   â”‚       â””â”€â”€ http_client.py       # HTTP utilities & retries
â”‚   â”‚
â”‚   â”œâ”€â”€ Dockerfile                  # Backend Docker configuration
â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json                # Frontend dependencies
â”‚   â”œâ”€â”€ next.config.js              # Next.js configuration
â”‚   â”œâ”€â”€ tailwind.config.js          # Tailwind CSS configuration
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/
â”‚       â”‚   â”œâ”€â”€ index.tsx            # News feed page
â”‚       â”‚   â””â”€â”€ favorites.tsx        # Favorites page
â”‚       â”‚
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ NewsCard.tsx         # News item UI component
â”‚       â”‚   â””â”€â”€ BroadcastModal.tsx   # Broadcast UI modal
â”‚       â”‚
â”‚       â””â”€â”€ lib/
â”‚           â””â”€â”€ api.ts               # API client & helpers
â”‚
â””â”€â”€ README.md                       # Project documentation
```



ğŸš€ How to Run Locally (Step-by-Step)
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Chahar48/AI-News-Aggregation-Broadcasting-Dashboard.git
cd AI_News_Dashboard

2ï¸âƒ£ Backend Setup
Create Virtual Environment
python -m venv venv

Activate Virtual Environment

#Windows
venv\Scripts\activate

#Mac/Linux
source venv/bin/activate

3ï¸âƒ£ Install Backend Dependencies
cd backend
pip install -r requirements.txt

4ï¸âƒ£ Setup PostgreSQL

Create a PostgreSQL database (via pgAdmin)
Update DB connection in .env or database.py

Example:

DATABASE_URL=postgresql://postgres:password@localhost:5432/ai_news_db

5ï¸âƒ£ Run Database Migrations / Create Tables
python -c "from app.models.db import Base, engine; Base.metadata.create_all(bind=engine)"

6ï¸âƒ£ Start Backend Server
uvicorn app.main:app --reload


Backend will run at:
http://127.0.0.1:8000


Swagger Docs:
http://127.0.0.1:8000/docs

7ï¸âƒ£ Frontend Setup
cd ../frontend
npm install
npm run dev


Frontend will run at:

http://localhost:3000


ğŸš€ Deployment (Dockerized Setup)

This project is fully containerized and can be run locally or deployed on any Docker-compatible platform (AWS, Render, Fly.io, DigitalOcean).

ğŸ“¦ Services Included

FastAPI Backend â€“ news ingestion, favorites, broadcast APIs
Next.js Frontend â€“ dashboard UI
PostgreSQL â€“ persistent database
RQ Worker â€“ async ingestion & broadcast jobs

ğŸ›  Prerequisites
Docker (v20+)
Docker Compose (v2+)

â–¶ï¸ Run Locally with Docker

From the project root:
docker-compose up --build

This will:

Build backend & frontend images
Start PostgreSQL with persistent storage
Start FastAPI backend
Start background worker
Start Next.js frontend

ğŸŒ Access URLs
Service	URL
Frontend Dashboard	http://localhost:3000
Backend API	http://localhost:8000
API Docs	http://localhost:8000/docs


ğŸ”„ How the System Works (End-to-End)
ğŸ” Ingestion

/api/v1/news/refresh

Uses seeded data (MVP mode)
Ensures sources exist
Normalizes news
Deduplicates
Saves to DB

ğŸ“° News Feed

/api/v1/news

Paginated feed
Displayed on dashboard

â­ Favorites

/api/v1/favorites
Save/remove favorites
Persistent DB storage

ğŸ“£ Broadcast

/api/v1/broadcast

Mock Email / LinkedIn / WhatsApp / Newsletter
Logs stored in broadcast_logs

ğŸ§ª API Endpoints (Core)
| Method | Endpoint                 | Purpose            |
| ------ | ------------------------ | ------------------ |
| GET    | `/api/v1/news`           | Get news feed      |
| POST   | `/api/v1/news/refresh`   | Refresh ingestion  |
| POST   | `/api/v1/favorites`      | Add favorite       |
| GET    | `/api/v1/favorites`      | List favorites     |
| POST   | `/api/v1/broadcast`      | Broadcast favorite |
| GET    | `/api/v1/broadcast/logs` | Broadcast history  |


Live scraping disabled (seeded data used)
No full-text search
No user authentication

ğŸ”® Future Improvements

Enable live RSS/API ingestion
Background ingestion jobs
Embedding-based deduplication
Full-text search & filters
Docker + CI/CD
Real Email/WhatsApp APIs

ğŸ Final Notes

This project was designed as a clean, reliable MVP that demonstrates:

System architecture
Backend engineering
AI integration
Database design
Frontend integration

All design decisions were made intentionally to maximize demo reliability and clarity.

ğŸ“¬ Contact

Mukesh Kumar
ğŸ“§ chaharmukesh518@gmail.com
ğŸ”— https://github.com/Chahar48 / https://www.linkedin.com/in/mukeshchahar/
